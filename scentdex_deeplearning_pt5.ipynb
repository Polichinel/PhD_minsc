{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import pickle\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pickle.load(open('X.pickle','rb'))\n",
    "y = pickle.load(open('y.pickle','rb'))\n",
    "X = X/255 # handon normalization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3_conv_32_nodes_0_1568354676\n",
      "WARNING:tensorflow:From C:\\Users\\xpn381\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\xpn381\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Train on 17462 samples, validate on 7484 samples\n",
      "Epoch 1/6\n",
      "17462/17462 [==============================] - 129s 7ms/sample - loss: 0.6493 - acc: 0.6128 - val_loss: 0.5824 - val_acc: 0.6932\n",
      "Epoch 2/6\n",
      "17462/17462 [==============================] - 137s 8ms/sample - loss: 0.5329 - acc: 0.7405 - val_loss: 0.5206 - val_acc: 0.7515\n",
      "Epoch 3/6\n",
      "17462/17462 [==============================] - 141s 8ms/sample - loss: 0.4693 - acc: 0.7818 - val_loss: 0.4592 - val_acc: 0.7811\n",
      "Epoch 4/6\n",
      "17462/17462 [==============================] - 121s 7ms/sample - loss: 0.4276 - acc: 0.8037 - val_loss: 0.4253 - val_acc: 0.8116\n",
      "Epoch 5/6\n",
      "17462/17462 [==============================] - 118s 7ms/sample - loss: 0.3902 - acc: 0.8246 - val_loss: 0.4076 - val_acc: 0.8112\n",
      "Epoch 6/6\n",
      "17462/17462 [==============================] - 136s 8ms/sample - loss: 0.3600 - acc: 0.8409 - val_loss: 0.3790 - val_acc: 0.8296\n",
      "done: 3_conv_32_nodes_0_1568354676\n",
      "\n",
      "4_conv_32_nodes_0_1568355458\n",
      "Train on 17462 samples, validate on 7484 samples\n",
      "Epoch 1/6\n",
      "17462/17462 [==============================] - 143s 8ms/sample - loss: 0.6487 - acc: 0.6112 - val_loss: 0.5889 - val_acc: 0.6792\n",
      "Epoch 2/6\n",
      "17462/17462 [==============================] - 144s 8ms/sample - loss: 0.5329 - acc: 0.7308 - val_loss: 0.5293 - val_acc: 0.7380\n",
      "Epoch 3/6\n",
      "17462/17462 [==============================] - 142s 8ms/sample - loss: 0.4782 - acc: 0.7736 - val_loss: 0.4993 - val_acc: 0.7580\n",
      "Epoch 4/6\n",
      "17462/17462 [==============================] - 144s 8ms/sample - loss: 0.4387 - acc: 0.7982 - val_loss: 0.4385 - val_acc: 0.7930\n",
      "Epoch 5/6\n",
      "17462/17462 [==============================] - 147s 8ms/sample - loss: 0.4117 - acc: 0.8126 - val_loss: 0.4196 - val_acc: 0.8040\n",
      "Epoch 6/6\n",
      "17462/17462 [==============================] - 138s 8ms/sample - loss: 0.3783 - acc: 0.8322 - val_loss: 0.4093 - val_acc: 0.8117\n",
      "done: 4_conv_32_nodes_0_1568355458\n",
      "\n",
      "3_conv_64_nodes_0_1568356317\n",
      "Train on 17462 samples, validate on 7484 samples\n",
      "Epoch 1/6\n",
      "17462/17462 [==============================] - 325s 19ms/sample - loss: 0.6383 - acc: 0.6222 - val_loss: 0.5460 - val_acc: 0.7320\n",
      "Epoch 2/6\n",
      "17462/17462 [==============================] - 330s 19ms/sample - loss: 0.5105 - acc: 0.7501 - val_loss: 0.4778 - val_acc: 0.7763\n",
      "Epoch 3/6\n",
      "17462/17462 [==============================] - 335s 19ms/sample - loss: 0.4521 - acc: 0.7884 - val_loss: 0.4468 - val_acc: 0.7906\n",
      "Epoch 4/6\n",
      "17462/17462 [==============================] - 297s 17ms/sample - loss: 0.4069 - acc: 0.8165 - val_loss: 0.4145 - val_acc: 0.8101\n",
      "Epoch 5/6\n",
      "17462/17462 [==============================] - 279s 16ms/sample - loss: 0.3685 - acc: 0.8394 - val_loss: 0.3922 - val_acc: 0.8204\n",
      "Epoch 6/6\n",
      "17462/17462 [==============================] - 268s 15ms/sample - loss: 0.3349 - acc: 0.8549 - val_loss: 0.4477 - val_acc: 0.7874\n",
      "done: 3_conv_64_nodes_0_1568356317\n",
      "\n",
      "4_conv_64_nodes_0_1568358151\n",
      "Train on 17462 samples, validate on 7484 samples\n",
      "Epoch 1/6\n",
      "17462/17462 [==============================] - 247s 14ms/sample - loss: 0.6496 - acc: 0.6109 - val_loss: 0.5915 - val_acc: 0.6807\n",
      "Epoch 2/6\n",
      "17462/17462 [==============================] - 273s 16ms/sample - loss: 0.5505 - acc: 0.7240 - val_loss: 0.5467 - val_acc: 0.7158\n",
      "Epoch 3/6\n",
      "17462/17462 [==============================] - 262s 15ms/sample - loss: 0.4759 - acc: 0.7732 - val_loss: 0.4484 - val_acc: 0.7904\n",
      "Epoch 4/6\n",
      "17462/17462 [==============================] - 317s 18ms/sample - loss: 0.4157 - acc: 0.8132 - val_loss: 0.4161 - val_acc: 0.8117\n",
      "Epoch 5/6\n",
      "17462/17462 [==============================] - 335s 19ms/sample - loss: 0.3747 - acc: 0.8327 - val_loss: 0.3949 - val_acc: 0.8334\n",
      "Epoch 6/6\n",
      "17462/17462 [==============================] - 345s 20ms/sample - loss: 0.3450 - acc: 0.8470 - val_loss: 0.3830 - val_acc: 0.8318\n",
      "done: 4_conv_64_nodes_0_1568358151\n",
      "\n",
      "3_conv_32_nodes_1_1568359931\n",
      "Train on 17462 samples, validate on 7484 samples\n",
      "Epoch 1/6\n",
      "17462/17462 [==============================] - 151s 9ms/sample - loss: 0.6441 - acc: 0.6146 - val_loss: 0.5778 - val_acc: 0.7040\n",
      "Epoch 2/6\n",
      "17462/17462 [==============================] - 151s 9ms/sample - loss: 0.5284 - acc: 0.7366 - val_loss: 0.4806 - val_acc: 0.7668\n",
      "Epoch 3/6\n",
      "17462/17462 [==============================] - 152s 9ms/sample - loss: 0.4611 - acc: 0.7846 - val_loss: 0.4353 - val_acc: 0.7946\n",
      "Epoch 4/6\n",
      "17462/17462 [==============================] - 122s 7ms/sample - loss: 0.4110 - acc: 0.8144 - val_loss: 0.4431 - val_acc: 0.7886\n",
      "Epoch 5/6\n",
      "17462/17462 [==============================] - 126s 7ms/sample - loss: 0.3767 - acc: 0.8330 - val_loss: 0.4122 - val_acc: 0.8069\n",
      "Epoch 6/6\n",
      "17462/17462 [==============================] - 132s 8ms/sample - loss: 0.3449 - acc: 0.8494 - val_loss: 0.4820 - val_acc: 0.7802\n",
      "done: 3_conv_32_nodes_1_1568359931\n",
      "\n",
      "4_conv_32_nodes_1_1568360767\n",
      "Train on 17462 samples, validate on 7484 samples\n",
      "Epoch 1/6\n",
      "17462/17462 [==============================] - 130s 7ms/sample - loss: 0.6588 - acc: 0.5984 - val_loss: 0.6174 - val_acc: 0.6530\n",
      "Epoch 2/6\n",
      "17462/17462 [==============================] - 125s 7ms/sample - loss: 0.5690 - acc: 0.7059 - val_loss: 0.5910 - val_acc: 0.6833\n",
      "Epoch 3/6\n",
      "17462/17462 [==============================] - 127s 7ms/sample - loss: 0.4854 - acc: 0.7680 - val_loss: 0.4473 - val_acc: 0.7952\n",
      "Epoch 4/6\n",
      "17462/17462 [==============================] - 152s 9ms/sample - loss: 0.4252 - acc: 0.8083 - val_loss: 0.4408 - val_acc: 0.7948\n",
      "Epoch 5/6\n",
      "17462/17462 [==============================] - 161s 9ms/sample - loss: 0.3852 - acc: 0.8255 - val_loss: 0.4060 - val_acc: 0.8131\n",
      "Epoch 6/6\n",
      "17462/17462 [==============================] - 154s 9ms/sample - loss: 0.3524 - acc: 0.8445 - val_loss: 0.3955 - val_acc: 0.8232\n",
      "done: 4_conv_32_nodes_1_1568360767\n",
      "\n",
      "3_conv_64_nodes_1_1568361618\n",
      "Train on 17462 samples, validate on 7484 samples\n",
      "Epoch 1/6\n",
      "17462/17462 [==============================] - 361s 21ms/sample - loss: 0.6276 - acc: 0.6325 - val_loss: 0.5315 - val_acc: 0.7397\n",
      "Epoch 2/6\n",
      " 7616/17462 [============>.................] - ETA: 2:27 - loss: 0.5226 - acc: 0.7451"
     ]
    }
   ],
   "source": [
    "dense_layers = [0,1]\n",
    "layer_sizes = [32, 64]\n",
    "conv_layers = [3,4]\n",
    "\n",
    "for dense_layer in dense_layers:\n",
    "    for layer_size in layer_sizes:\n",
    "        for conv_layer in conv_layers:\n",
    "            NAME = f'{conv_layer}_conv_{layer_size}_nodes_{dense_layer}_{int(time.time())}'\n",
    "            print(NAME)\n",
    "            \n",
    "            model = Sequential()\n",
    "            \n",
    "            # 1. conv layer\n",
    "            model.add(Conv2D(layer_size, (3,3), input_shape = X.shape[1:])) # can skip the first entry X.shape[0]\n",
    "            model.add(Activation('relu'))\n",
    "            model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "            \n",
    "            for l in range(conv_layer-1): # -1 since you have ine conv layer above\n",
    "                # x number of conv layers\n",
    "                model.add(Conv2D(layer_size, (3,3)))\n",
    "                model.add(Activation('relu'))\n",
    "                model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "            model.add(Flatten()) # from 2D to 1D. need both of pontial dense layers and output layer\n",
    "            for l in range(dense_layer):\n",
    "                # x number of dense layers\n",
    "                model.add(Dense(layer_size)) # should proberly not be the same as the conv\n",
    "                model.add(Activation('relu'))\n",
    "\n",
    "            # ouyput layer\n",
    "            model.add(Dense(1))\n",
    "            model.add(Activation('sigmoid'))\n",
    "            \n",
    "            tensorboard = TensorBoard(log_dir = f'logs\\\\{NAME}') # \\\\ bc windows...\n",
    "\n",
    "            model.compile(loss='binary_crossentropy',\n",
    "                         optimizer='adam',\n",
    "                         metrics=['accuracy'])\n",
    "\n",
    "            model.fit(X, y, batch_size=32, epochs=6, validation_split=0.3, callbacks=[tensorboard]) # batch 20-200 depends on the size of you dataset\n",
    "            print(f'done: {NAME}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## to use Tensorboard:\n",
    "open er terminal through jupyter\n",
    "\n",
    ">cd \"C:\\Users\\xpn381\\Documents\\Python Scripts\" \\\n",
    ">tensorboard --logdir=\"logs/\" --host localhost --port 8088\n",
    "\n",
    "#Then navigated the browser to http://localhost:8088"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
